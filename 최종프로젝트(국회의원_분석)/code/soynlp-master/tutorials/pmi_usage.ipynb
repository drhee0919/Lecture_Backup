{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive Point Mutual Information\n",
    "\n",
    "Point Mutual Information (PMI) 는 (word, contexts) 이나 (input, outputs) 와의 상관성을 측정하는 방법입니다. 두 변수 $x$, $y$ 의 상관성은 다음처럼 정의됩니다. 서로 상관이 없는 변수 $x$, $y$의 pmi 는 0 이며, 그 값이 클수록 positive correlated 있습니다. \n",
    "\n",
    "- $pmi(x,y) = log \\left( \\frac{p(x,y)}{p(x) \\times p(y)} \\right )$\n",
    "\n",
    "Positive PMI 는 음의 값을 지니는 PMI 를 모두 0으로 치환합니다. \n",
    "\n",
    "- $ppmi(x,y) = max(0, log \\left( \\frac{p(x,y)}{p(x) \\times p(y)} \\right)$\n",
    "\n",
    "그런데 PMI 는 infrequent $y$ 에 대하여 그 값이 지나치게 예민합니다. 이를 보완하기 위하여 smoothing 을 할 수 있습니다. soynlp 에서는 다음과 같은 smoothing 방법을 이용합니다. $\\alpha$ 를 $p(y)$ 에 더합니다. \n",
    "\n",
    "- $pmi(x,y) = log \\left( \\frac{p(x,y)}{p(x) \\times \\left( p(y) + \\alpha \\right)} \\right)$\n",
    "\n",
    "$\\alpha$ 는 y 의 threshold 역할을 합니다. PMI 는 다음처럼 기술될 수 있습니다. $p(y)$ 가 $\\alpha$ 보다 큰 값들이 positive pmi value 를 지닐 수 있습니다. \n",
    "\n",
    "- $pmi(x,y) = \\frac{p(y \\vert x)}{\\left( p(y) + \\alpha \\right)}$\n",
    "\n",
    "PPMI 를 위해서 min_pmi 를 기준으로 threshold cutting 을 하는 기능도 제공합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word - context matrix\n",
    "\n",
    "Word - context 그래프는 단어의 문맥을 파악하기 위해 사용될 수 있습니다. \n",
    "\n",
    "sentence = ['a', 'little', 'cat', 'sit', 'on', 'table'] , window = 2 일 때, 'cat' 의 context words 는 ['a', 'little', 'sit', 'on'] 입니다. sent_to_word_context_matrix() 함수는 이 역할을 수행합니다. min_tf 는 minimum frequency 입니다. \n",
    "\n",
    "Return 은 scipy.sparse.csr.csr_matrix 형식의 word - context matrix 와 list of str 형식의 vocabulary list 입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.49\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import soynlp\n",
    "print(soynlp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용할 토크나이저를 학습합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num sents = 223357\n",
      "training was done. used memory 0.724 Gbse memory 0.777 Gb\n",
      "all cohesion probabilities was computed. # words = 223348\n",
      "(0.487322733132789, 0.22771099423991986)\n",
      "['하루', '의', '뉴스', '를', '학습', '했습니다']\n"
     ]
    }
   ],
   "source": [
    "from soynlp import DoublespaceLineCorpus\n",
    "from soynlp.word import WordExtractor\n",
    "from soynlp.tokenizer import LTokenizer\n",
    "\n",
    "corpus_path = '2016-10-20.txt'\n",
    "corpus = DoublespaceLineCorpus(corpus_path, iter_sent = True)\n",
    "print('num sents = {}'.format(len(corpus)))\n",
    "\n",
    "word_extractor = WordExtractor()\n",
    "word_extractor.train(corpus)\n",
    "cohesions = word_extractor.all_cohesion_scores()\n",
    "print(cohesions['뉴스'])\n",
    "\n",
    "l_cohesions = {word:score[0] for word, score in cohesions.items()}\n",
    "tokenizer = LTokenizer(l_cohesions)\n",
    "print(tokenizer('하루의 뉴스를 학습했습니다'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sent_to_word_contexts_matrix() 에 window, min_tf, tokenizer 를 넣습니다. verbose=True 이면 vectorizing 되는 상태의 모니터링이 가능합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create (word, contexts) matrix\n",
      "  - counting word frequency from 223356 sents, mem=0.726 Gb\n",
      "  - scanning (word, context) pairs from 223356 sents, mem=1.184 Gb\n",
      "  - (word, context) matrix was constructed. shape = (48583, 48583)                    \n",
      "  - done\n"
     ]
    }
   ],
   "source": [
    "from soynlp.vectorizer import sent_to_word_contexts_matrix\n",
    "\n",
    "x, idx2vocab = sent_to_word_contexts_matrix(\n",
    "    corpus,\n",
    "    windows = 3,\n",
    "    min_tf = 10,\n",
    "    tokenizer = tokenizer, # (default) lambda x:x.split(),\n",
    "    dynamic_weight = False,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMI\n",
    "\n",
    "soynlp.word.pmi 는 x 의 (rows, columns) 에 대한 pmi 를 계산합니다. row 가 x, column 이 y 입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.word import pmi as pmi_func\n",
    "\n",
    "pmi, px, py = pmi_func(\n",
    "    x,\n",
    "    min_pmi = 0,\n",
    "    alpha = 0.0,\n",
    "    beta = 0.75\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 `아이오아이` 와 pmi 가 높은 (`아이오아이` 주변에 자주 등장한) 단어를 찾습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('신용재', 7.141024243363501),\n",
      " ('완전체로', 7.015931333051887),\n",
      " ('후크송으로', 6.977172538792954),\n",
      " ('세븐', 6.830966065152642),\n",
      " ('오블리스', 6.717087720696372),\n",
      " ('신용재가', 6.670209432230605),\n",
      " ('정채연은', 6.560811696929447),\n",
      " ('상큼한', 6.334895661765805),\n",
      " ('선배님들이', 6.154353835218832),\n",
      " ('금빛나', 5.878560250124844)]\n"
     ]
    }
   ],
   "source": [
    "vocab2idx = {vocab:idx for idx, vocab in enumerate(idx2vocab)}\n",
    "query = vocab2idx['아이오아이']\n",
    "\n",
    "submatrix = pmi[query,:].tocsr() # get the row of query\n",
    "contexts = submatrix.nonzero()[1] # nonzero() return (rows, columns)\n",
    "pmi_i = submatrix.data\n",
    "\n",
    "most_relateds = [(idx, pmi_ij) for idx, pmi_ij in zip(contexts, pmi_i)]\n",
    "most_relateds = sorted(most_relateds, key=lambda x:-x[1])[:10]\n",
    "most_relateds = [(idx2vocab[idx], pmi_ij) for idx, pmi_ij in most_relateds]\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(most_relateds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 `아이오아이` 와 유사한 contexts vector 를 지닌 단어를 찾습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('엠카운트다운', 0.2510761472706349),\n",
       " ('너무너무', 0.24962359995756267),\n",
       " ('신용재', 0.24854244222409871),\n",
       " ('갓세븐', 0.20190168259477226),\n",
       " ('컴백', 0.20040893958615869),\n",
       " ('완전체로', 0.1971543262212967),\n",
       " ('걸그룹', 0.19516713512611328),\n",
       " ('엠카', 0.1870115403151804),\n",
       " ('오블리스', 0.18510781764378215),\n",
       " ('다비치', 0.1827054015470695)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.utils import most_similar\n",
    "\n",
    "most_similar('아이오아이', pmi, vocab2idx, idx2vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
